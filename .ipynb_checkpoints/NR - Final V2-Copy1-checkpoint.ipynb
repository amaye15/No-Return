{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/typhaine/Documents/Doc Gorilla/WhereIsMyMNIST/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/typhaine/Documents/Doc Gorilla/WhereIsMyMNIST/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 28,\n",
       " 'minibatch_size': 100,\n",
       " 'train_batch_size': 50000,\n",
       " 'test_batch_size': 10000,\n",
       " 'noise_batch_size': 1000,\n",
       " 'mean': 0.1307,\n",
       " 'std': 0.3081,\n",
       " 'what_offset_std': 15,\n",
       " 'what_offset_max': 25,\n",
       " 'N_pic': 128,\n",
       " 'offset_std': 30,\n",
       " 'offset_max': 34,\n",
       " 'noise': 0.75,\n",
       " 'contrast': 0.7,\n",
       " 'sf_0': 0.1,\n",
       " 'B_sf': 0.1,\n",
       " 'do_mask': True,\n",
       " 'N_theta': 6,\n",
       " 'N_azimuth': 24,\n",
       " 'N_eccentricity': 10,\n",
       " 'N_phase': 2,\n",
       " 'rho': 1.41,\n",
       " 'bias_deconv': True,\n",
       " 'p_dropout': 0.0,\n",
       " 'dim1': 1000,\n",
       " 'dim2': 1000,\n",
       " 'lr': 0.005,\n",
       " 'do_adam': True,\n",
       " 'bn1_bn_momentum': 0.5,\n",
       " 'bn2_bn_momentum': 0.5,\n",
       " 'momentum': 0.3,\n",
       " 'epochs': 60,\n",
       " 'num_processes': 1,\n",
       " 'no_cuda': False,\n",
       " 'log_interval': 100,\n",
       " 'verbose': 1,\n",
       " 'filename': '../data/2019-06-12',\n",
       " 'seed': 2019,\n",
       " 'N_cv': 10,\n",
       " 'do_compute': True,\n",
       " 'save_model': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import IterableDataset, ChainDataset, DataLoader\n",
    "\n",
    "\n",
    "import pygame\n",
    "from psychopy import visual, core, event, gui, data\n",
    "\n",
    "from what import WhatShift, WhatBackground, WhatNet, WhatTrainer, What, train, test, MNIST, MotionCloudNoise\n",
    "import MotionClouds as mc\n",
    "\n",
    "from main import init\n",
    "args = init(filename='../data/2019-06-12') # pas de drop out!\n",
    "args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Iterable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7d7be71c6f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mChainDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     r\"\"\"Dataset for chainning multiple :class:`IterableDataset` s.\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0museful\u001b[0m \u001b[0mto\u001b[0m \u001b[0massemble\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mexisting\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mchainning\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdone\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthe\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mso\u001b[0m \u001b[0mconcatenating\u001b[0m \u001b[0mlarge\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7d7be71c6f78>\u001b[0m in \u001b[0;36mChainDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdatasets\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m \u001b[0mof\u001b[0m \u001b[0mIterableDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mchained\u001b[0m \u001b[0mtogether\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChainDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Iterable' is not defined"
     ]
    }
   ],
   "source": [
    "class ChainDataset(IterableDataset):\n",
    "    def __init__(self, datasets: Iterable[Dataset]):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __iter__(self):\n",
    "        for d in self.datasets:\n",
    "            assert isinstance(d, IterableDataset), \"ChainDataset only supports IterableDataset\"\n",
    "            for x in d:\n",
    "                yield x\n",
    "\n",
    "    def __len__(self):\n",
    "        total = 0\n",
    "        for d in self.datasets:\n",
    "            assert isinstance(d, IterableDataset), \"ChainDataset only supports IterableDataset\"\n",
    "            # Cannot verify that all self.datasets are Sized\n",
    "            total += len(d)  # type: ignore\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_1=transforms.Compose([\n",
    "                               WhatShift(args,\n",
    "                                         i_offset=random.randint(-50,50), \n",
    "                                         j_offset=random.randint(-50,50)),\n",
    "                               WhatBackground(contrast = args.contrast,\n",
    "                                              noise=0.5, \n",
    "                                              sf_0=args.sf_0, \n",
    "                                              B_sf=args.B_sf),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((args.mean,), (args.std,))\n",
    "                           ])\n",
    "\n",
    "dataset_train_1 = MNIST('../data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform_1,\n",
    "                        )\n",
    "transform_2=transforms.Compose([\n",
    "                               WhatShift(args,\n",
    "                                         i_offset=random.randint(-50,0), \n",
    "                                         j_offset=random.randint(-50,0)),\n",
    "                               WhatBackground(contrast = args.contrast,\n",
    "                                              noise=0.5, \n",
    "                                              sf_0=args.sf_0, \n",
    "                                              B_sf=args.B_sf),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((args.mean,), (args.std,))\n",
    "                           ])\n",
    "\n",
    "dataset_train_2 = MNIST('../data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform_2,\n",
    "                        )\n",
    "\n",
    "transform_3 =transforms.Compose([\n",
    "                               WhatShift(args,\n",
    "                                         i_offset=random.randint(-50,0), \n",
    "                                         j_offset=random.randint(0,50)),\n",
    "                               WhatBackground(contrast = args.contrast,\n",
    "                                              noise=0.5, \n",
    "                                              sf_0=args.sf_0, \n",
    "                                              B_sf=args.B_sf),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((args.mean,), (args.std,))\n",
    "                           ])\n",
    "\n",
    "dataset_train_3 = MNIST('../data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform_3,\n",
    "                        )\n",
    "\n",
    "transform_4 =transforms.Compose([\n",
    "                               WhatShift(args,\n",
    "                                         i_offset=random.randint(0,50), \n",
    "                                         j_offset=random.randint(-50,0)),\n",
    "                               WhatBackground(contrast = args.contrast,\n",
    "                                              noise=0.5, \n",
    "                                              sf_0=args.sf_0, \n",
    "                                              B_sf=args.B_sf),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((args.mean,), (args.std,))\n",
    "                           ])\n",
    "\n",
    "dataset_train_4 = MNIST('../data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform_4,\n",
    "                        )\n",
    "    \n",
    "train_loader = DataLoader(ChainDataset([dataset_train_1,dataset_train_2]),\n",
    "                                         batch_size=2,\n",
    "                                         shuffle=False)\n",
    "\n",
    "data,label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'psychopy.data' has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-45097fce6890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'psychopy.data' has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label[0].shape)\n",
    "print(label)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "maximum() missing 1 required positional arguments: \"other\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-bb5f3f57827b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#save = torch.maximum(data1[0],(data2[0],data3[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#temp = np.repeat(temp,60).reshape(128,128,60)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: maximum() missing 1 required positional arguments: \"other\""
     ]
    }
   ],
   "source": [
    "#save = torch.maximum(data1[0],(data2[0],data3[0]))\n",
    "temp = torch.maximum(data)\n",
    "\n",
    "#temp = np.repeat(temp,60).reshape(128,128,60)\n",
    "print(temp.shape)\n",
    "#temp = np.tile((temp),60).reshape(128,128,60)\n",
    "plt.imshow(temp[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
